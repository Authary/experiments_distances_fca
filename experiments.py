import ot
import copy
import PCA
import math
import random
from matplotlib import pyplot as plt
import numpy as np
import scipy.stats as ss
import threading
import time
import statistics
from scipy.spatial import distance
import setFTs as SFT
from mpl_toolkits import mplot3d
from bitsets import bitset

#Computes the lexicographic tree of the union-closed family F generated by B
def tree(B):
    F = [set()]
    gamma = [[]]
    for b in B:
        indice = 0
        while indice < len(F):
            f = F[indice]
            fp = f.union(b)
            if fp not in F:
                F.append(fp)
                gamma.append([])
            if b not in gamma[F.index(fp)]:
                gamma[F.index(fp)].append(b)
            indice += 1
    return F,gamma
            

#Computes the covering graph of the union-closed family Fb and gamma(f) for every member f of F
def coveringGraph(Fb,gamma,B):
    COUNT = []
    ImSucc = []
    for i in range(len(Fb)):
        COUNT.append(0)
        ImSucc.append([])
    for i in range(len(Fb)):
        for b in B:
            if b not in gamma[i]:
                Fp = Fb[i].union(b)
                index = Fb.index(Fp)
                COUNT[index] += 1
                if len(gamma[index]) == COUNT[index] + len(gamma[i]):
                    ImSucc[i] += [Fp]
        COUNT = []
        for j in range(len(Fb)):
            COUNT.append(0)
    return ImSucc


#computes "the Adjacency lists ImSucc of the covering graph of the lattice (FB , ⊆)"
def UCS(B):
    FB,gamma = tree(B)
    return coveringGraph(FB,gamma,B),FB


#Computes the Dedekind-Macneille completion of the input set of extents
def DMC(Extents,nbObjects):
    allObj = set(list(range(nbObjects)))
    B = [allObj.difference(E) for E in Extents]
    B.sort(key = len)
    F,gamma = tree(B)

    for f in range(len(F)):
        F[f] = allObj.difference(F[f])

    return F

#Computes the Jaccard index of two sets
def Jaccard(set1,set2):
    if len(set1)+len(set2) == 0:
        return 1
    else:
        return len(set1.intersection(set2))/len(set1.union(set2))


#Changes a context
def closeEnoughContext(C, p):
    context = copy.deepcopy(C)
    tries = int(math.log2(context[1]))
    changes = 0
    for i in range(tries):
        index = random.randint(0,len(context[0])-1)
        test = random.random()
        if test < p/2 :
            if random.random() < 0.5 :
                if context[0][index][0] > 0 :
                    context[0][index][0] -= 1
                    changes += 1
                else :
                    context[0][index][0] = context[1]-1
                    changes += 1
            else :
                if context[0][index][0] < context[1]-1:
                    context[0][index][0] += 1
                    changes += 1
                else :
                    context[0][index][0] = 0
                    changes += 1
        elif test >= p/2 and test < p :
            if random.random() < 0.5 :
                if context[0][index][1] > 0 :
                    context[0][index][1] -= 1
                    changes +=1
                else :
                    context[0][index][1] = context[2]-1
                    changes += 1
            else :
                if context[0][index][1] < context[2]-1:
                    context[0][index][1] += 1
                    changes += 1
                else :
                    context[0][index][1] = 0
                    changes += 1
    return context, changes

#Changes a context
def closeEnoughContext2(C, p):
    context = copy.deepcopy(C)
    changes = 0
    for x in context[0]:
        index = random.randint(0,len(context[0])-1)
        test = random.random()
        if test < p :
            test2 = random.random()
            if test2 < 0.5 :
                x[0] = random.randint(0,context[1]-1)
            else:
                x[1] = random.randint(0,context[2]-1)
           
    return context

def closeEnoughContext3(C, p):
    context = copy.deepcopy(C)
    tries = int(math.log2(context[1]))
    changes = 0
    for index in range(0,len(context[0])-1):
        test = random.random()
        if test < p/2 :
            if random.random() < 0.5 :
                if context[0][index][0] > 0 :
                    context[0][index][0] -= 1
                    changes += 1
                else :
                    context[0][index][0] = context[1]-1
                    changes += 1
            else :
                if context[0][index][0] < context[1]-1:
                    context[0][index][0] += 1
                    changes += 1
                else :
                    context[0][index][0] = 0
                    changes += 1
        elif test >= p/2 and test < p :
            if random.random() < 0.5 :
                if context[0][index][1] > 0 :
                    context[0][index][1] -= 1
                    changes +=1
                else :
                    context[0][index][1] = context[2]-1
                    changes += 1
            else :
                if context[0][index][1] < context[2]-1:
                    context[0][index][1] += 1
                    changes += 1
                else :
                    context[0][index][1] = 0
                    changes += 1
    return context, changes

def closeEnoughContext4(C,p):
    context = copy.deepcopy(C)
    for i in range(context[1]):
        for j in range(context[2]):
            test = random.random()
            if test < p:
                if [i,j] in context[0]:
                    context[0].remove([i,j])
                else:
                    context[0].append([i,j])
    return context


#Returns a d1xd2 random context with uniform probability p
def randomContext(d1,d2, p):
    context = []
    for i in range(d1):
        for j in range(d2):
            if random.random() < p :
                context.append([i,j])
    result = [context, d1, d2]
    return(result)


'''
measures
'''

#Computes the EMD of two 2D contexts over the same dimensions
def Earth_mover_distance(context1,context2):
    a = np.zeros((context1[1],context1[2]))
    b = np.zeros((context2[1],context2[2]))

    for [x,y] in context1[0]:
        a[x,y] += 1
    for [x,y] in context2[0]:
        b[x,y] += 1
    a /= np.sum(a)
    b /= np.sum(b)

    a = a.reshape((1,context1[1]*context1[2]))[0]
    b = b.reshape((1,context2[1]*context2[2]))[0]

    M = np.zeros((context1[1]*context1[2],context2[1]*context2[2]))
    for i in range(context1[1]):
        for j in range(context1[2]):
            for x in range(context2[1]):
                for y in range(context2[2]):
                    dist = 0
                    if i != x:
                        dist += 1
                    if j != y:
                        dist += 1
                    M[i*context1[2]+j,x*context2[2]+y] = dist
                    M[x*context2[2]+y,i*context1[2]+j] = dist
    
    G0 = ot.emd(a, b, M)

    somm = 0
    for i in range(context1[1]*context1[2]):
        for j in range(context2[1]*context2[2]):
            somm += G0[i,j]*M[i,j]
    
    return somm


#Computes the distance between two concept lattices
def lattice_distance(L1,L2):
    class Concept:
        def __init__(self, c, b, t):
            self.c = c
            self.b = b
            self.t = t   

    Extents = [E for [E,I] in L1]
    for [E,I] in L2:
        if E not in Extents:
            Extents += [E]
    
    nbObj = max([len(E) for E in Extents])

    Comp = DMC(Extents,nbObj)

    #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    dict = {}
    CL2 = [Concept(X,0,0) for X in Comp]
    for i in range(len(Comp)):
        dict[i] = []
        for conc in CL2:
            if conc.c.issubset(CL2[i].c) and not set(CL2[i].c).issubset(conc.c):
                dict[i].append(conc)

    #Calcul des classes d'équivalences
    end = 0
    while end == 0:
        end = 1
        for i in range(len(CL2)):
            if CL2[i].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1:
                    end = 0
                    CL2[i].t = pow(2,(len(CL2[i].c)))-sum
                    CL2[i].b = 1  

    #Calcul des intersections
    somm = 0
    for i in range(len(CL2)):
        Ex = CL2[i].c
        smallestSuperExtent1 = set(range(max([len(E) for E in Extents])))
        sIntent1 = set()
        smallestSuperExtent2 = set(range(max([len(E) for E in Extents])))
        sIntent2 = set()
        for [E,I] in L1:
            if Ex.issubset(E) and E.issubset(smallestSuperExtent1):
                smallestSuperExtent1 = E
                sIntent1 = I
        for [E,I] in L2:
            if Ex.issubset(E) and E.issubset(smallestSuperExtent2):
                smallestSuperExtent2 = E
                sIntent2 = I
        somm += CL2[i].t*(1-Jaccard(sIntent1,sIntent2))

    return somm#/pow(2,nbObj)





#Computes the distance between two proper premises bases
def implication_distance_euclidean(Imps1,Imps2,nbAtt):
    
    somm = 0

    for a in range(nbAtt):
        #print("=======================")
        #print("Attribut : ",a)
        #print("=======================")
        #récupérer les premisses de a
        premisses_de_a_1 = []
        premisses_de_a_2 = []
        for [A,B] in Imps1:
            if a in B:
                premisses_de_a_1.append(A)
        for [A,B] in Imps2:
            if a in B:
                premisses_de_a_2.append(A)
        #print("Premisses 1 : ",premisses_de_a_1)
        #print("Premisses 2 : ",premisses_de_a_2)

        #calculer les intersections des premisses
        intersections_premisses = []
        for A in premisses_de_a_1:
            for B in premisses_de_a_2:
                I = set(A).union(set(B))
                if I not in intersections_premisses:
                    intersections_premisses.append(I)
        aVirer = []
        for I in intersections_premisses:
            virer = False
            for I2 in intersections_premisses:
                if I2.issubset(I) and len(I) != len(I2):
                    virer = True
                    break
            if virer:
                aVirer.append(I)
        for I in aVirer:
            intersections_premisses.remove(I)
        if len(premisses_de_a_1) == 0 and len(premisses_de_a_2) != 0:
            intersections_premisses = premisses_de_a_1
        if len(premisses_de_a_2) == 0 and len(premisses_de_a_1) != 0:
            intersections_premisses = premisses_de_a_2

        #calculer l'union des premisses
        union_premisses = [set(x) for x in premisses_de_a_1]
        for A in premisses_de_a_2:
            if set(A) not in union_premisses:
                union_premisses.append(set(A))
        aVirer = []
        for I in union_premisses:
            virer = False
            for I2 in union_premisses:
                if I2.issubset(I) and len(I) != len(I2):
                    virer = True
                    break
            if virer:
                aVirer.append(I)
        for I in aVirer:
            union_premisses.remove(I)
        if len(premisses_de_a_1) == 0 and len(premisses_de_a_2) != 0:
            union_premisses = premisses_de_a_2
        if len(premisses_de_a_2) == 0 and len(premisses_de_a_1) != 0:
            union_premisses = premisses_de_a_1

        #print("Union des premisses : ",union_premisses)
        #print("Intersection des premisses : ",intersections_premisses)

        #Dedekind-Macneille completion des premisses
        if len(intersections_premisses) > 0:
            Comp1,_ = tree(intersections_premisses)
        else:
            Comp1 = []
        if len(union_premisses) > 0:
            Comp2,_ = tree(union_premisses)
        else:
            Comp2 = []

        #print("DMC_inter : ",Comp1)
        #print("DMC_union : ",Comp2)

        class Concept:
            def __init__(self, c, b, t):
                self.c = c
                self.b = b
                self.t = t
        #Calcul pour les intersections
        classe_max_intersection = 0
        dict = {}
        CL2 = [Concept(X,0,0) for X in Comp1]
        #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
        for i in range(len(CL2)):
            dict[i] = []
            for conc in CL2:
                if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                    dict[i].append(conc)
        #Calcul des classes d'équivalences
        end = 0
        while end == 0:
            end = 1
            for i in range(len(CL2)):
                if CL2[i].b == 0:
                    aTraiter = 1
                    sum = 0
                    for conc2 in dict[i]:
                        if conc2.b == 0:
                            aTraiter = 0
                            break
                        sum += conc2.t
                    if aTraiter == 1 and (len(CL2[i].c) > 0 or len(CL2) == 1):
                        end = 0
                        CL2[i].t = pow(2,(nbAtt-len(CL2[i].c)-1))-sum
                        classe_max_intersection += CL2[i].t
                        CL2[i].b = 1

        #for C in CL2:
        #    print("Premisse ",C.c," |classe| ",C.t)


        #Calcul pour les unions
        classe_max_union = 0
        dict = {}
        CL2 = [Concept(X,0,0) for X in Comp2]
        #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
        for i in range(len(CL2)):
            dict[i] = []
            for conc in CL2:
                if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                    dict[i].append(conc)
        #Calcul des classes d'équivalences
        end = 0
        while end == 0:
            end = 1
            for i in range(len(CL2)):
                if CL2[i].b == 0:
                    aTraiter = 1
                    sum = 0
                    for conc2 in dict[i]:
                        if conc2.b == 0:
                            aTraiter = 0
                            break
                        sum += conc2.t
                    if aTraiter == 1 and (len(CL2[i].c) > 0 or len(CL2) == 1):
                        end = 0
                        CL2[i].t = pow(2,(nbAtt-len(CL2[i].c)-1))-sum
                        classe_max_union += CL2[i].t
                        CL2[i].b = 1

        #for C in CL2:
        #    print("Premisse ",C.c," |classe| ",C.t)

        #print("Taille Intersection ",classe_max_intersection)
        #print("Taille Union ",classe_max_union)
        #if(classe_max_union > 0):
        #    print("Jaccard = ",classe_max_intersection/classe_max_union)
        #else:
        #    print("Jaccard = ",1)

        if classe_max_union > 0:
            somm += (1-(classe_max_intersection/classe_max_union))**2
        else:
            somm += 0

    return math.sqrt(somm)

        
#Computes the distance between two proper premises bases
def implication_distance_euclidean_MT(Imps1,Imps2,nbAtt):
    
    somm = 0
    threads = []
    results = []
    for a in range(nbAtt):
        t = threading.Thread(target=impli_ter, args=(Imps1,Imps2,nbAtt,a,results))
        t.start()
        threads.append(t)
    for thread in threads:
        thread.join()
        

    return math.sqrt(sum(results))    

def impli_ter(Imps1,Imps2,nbAtt,a,result):   
    premisses_de_a_1 = []
    premisses_de_a_2 = []
    for [A,B] in Imps1:
        if a in B:
            premisses_de_a_1.append(A)
    for [A,B] in Imps2:
        if a in B:
            premisses_de_a_2.append(A)
    #print("Premisses 1 : ",premisses_de_a_1)
    #print("Premisses 2 : ",premisses_de_a_2)

    #calculer les intersections des premisses
    intersections_premisses = []
    for A in premisses_de_a_1:
        for B in premisses_de_a_2:
            I = set(A).union(set(B))
            if I not in intersections_premisses:
                intersections_premisses.append(I)
    aVirer = []
    for I in intersections_premisses:
        virer = False
        for I2 in intersections_premisses:
            if I2.issubset(I) and len(I) != len(I2):
                virer = True
                break
        if virer:
            aVirer.append(I)
    for I in aVirer:
        intersections_premisses.remove(I)
    if len(premisses_de_a_1) == 0 and len(premisses_de_a_2) != 0:
        intersections_premisses = premisses_de_a_1
    if len(premisses_de_a_2) == 0 and len(premisses_de_a_1) != 0:
        intersections_premisses = premisses_de_a_2

    #calculer l'union des premisses
    union_premisses = [set(x) for x in premisses_de_a_1]
    for A in premisses_de_a_2:
        if set(A) not in union_premisses:
            union_premisses.append(set(A))
    aVirer = []
    for I in union_premisses:
        virer = False
        for I2 in union_premisses:
            if I2.issubset(I) and len(I) != len(I2):
                virer = True
                break
        if virer:
            aVirer.append(I)
    for I in aVirer:
        union_premisses.remove(I)
    if len(premisses_de_a_1) == 0 and len(premisses_de_a_2) != 0:
        union_premisses = premisses_de_a_2
    if len(premisses_de_a_2) == 0 and len(premisses_de_a_1) != 0:
        union_premisses = premisses_de_a_1

    #print("Union des premisses : ",union_premisses)
    #print("Intersection des premisses : ",intersections_premisses)

    #Dedekind-Macneille completion des premisses
    if len(intersections_premisses) > 0:
        Comp1,_ = tree(intersections_premisses)
    else:
        Comp1 = []
    if len(union_premisses) > 0:
        Comp2,_ = tree(union_premisses)
    else:
        Comp2 = []

    #print("DMC_inter : ",Comp1)
    #print("DMC_union : ",Comp2)

    class Concept:
        def __init__(self, c, b, t):
            self.c = c
            self.b = b
            self.t = t
    #Calcul pour les intersections
    classe_max_intersection = 0
    dict = {}
    CL2 = [Concept(X,0,0) for X in Comp1]
    #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    for i in range(len(CL2)):
        dict[i] = []
        for conc in CL2:
            if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                dict[i].append(conc)
    #Calcul des classes d'équivalences
    end = 0
    while end == 0:
        end = 1
        for i in range(len(CL2)):
            if CL2[i].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1 and (len(CL2[i].c) > 0 or len(CL2) == 1):
                    end = 0
                    CL2[i].t = pow(2,(nbAtt-len(CL2[i].c)-1))-sum
                    classe_max_intersection += CL2[i].t
                    CL2[i].b = 1

    #for C in CL2:
    #    print("Premisse ",C.c," |classe| ",C.t)


    #Calcul pour les unions
    classe_max_union = 0
    dict = {}
    CL2 = [Concept(X,0,0) for X in Comp2]
    #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    for i in range(len(CL2)):
        dict[i] = []
        for conc in CL2:
            if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                dict[i].append(conc)
    #Calcul des classes d'équivalences
    end = 0
    while end == 0:
        end = 1
        for i in range(len(CL2)):
            if CL2[i].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1 and (len(CL2[i].c) > 0 or len(CL2) == 1):
                    end = 0
                    CL2[i].t = pow(2,(nbAtt-len(CL2[i].c)-1))-sum
                    classe_max_union += CL2[i].t
                    CL2[i].b = 1

    #for C in CL2:
    #    print("Premisse ",C.c," |classe| ",C.t)

    #print("Taille Intersection ",classe_max_intersection)
    #print("Taille Union ",classe_max_union)
    #if(classe_max_union > 0):
    #    print("Jaccard = ",classe_max_intersection/classe_max_union)
    #else:
    #    print("Jaccard = ",1)

    if classe_max_union > 0:
        result.append((1-(classe_max_intersection/classe_max_union))**2)
    else:
        result.append(0)


def jensenShannon(context1, context2) :
    a = np.zeros((context1[1],context1[2]))
    b = np.zeros((context2[1],context2[2]))

    for [x,y] in context1[0]:
        a[x,y] += 1
    for [x,y] in context2[0]:
        b[x,y] += 1
    a /= np.sum(a)
    b /= np.sum(b)

    a = a.reshape((1,context1[1]*context1[2]))[0]
    b = b.reshape((1,context2[1]*context2[2]))[0]
    print(distance.jensenshannon(a, b, 2))


def powerset(s):
    x = len(s)
    masks = [1 << i for i in range(x)]
    for i in range(1 << x):
        yield [ss for mask, ss in zip(masks, s) if i & mask]

#Align frequencies (in this case elements of the cube) and coefs in a 2^dimension list
def alignCoefsFreqsToCube (coefs, freqs, NbObj) :
	frequencies = freqs.tolist()
	coefficients = coefs.tolist()
	dimension = len(frequencies[0])

	cube = bitset('cube', range(NbObj))
	setOfFreqs = set()
	for freq in frequencies :
		setOfFreqs.add(int(cube.frombits("".join(str(e) for e in freq))))

	res_freqs = list()
	res_coefs = list()
	for i in range(2**NbObj) :
		if i in setOfFreqs :
			res_coefs.append(coefficients.pop(0))
		else :
			res_coefs.append(0)
		res_freqs.append(cube.fromint(i))
	return res_coefs, res_freqs

def distances (ft1, ft2) :

	return float(stats.wasserstein_distance(ft1, ft2)), float(distance.euclidean(ft1,ft2))

def assignSignalLattice(dimension,Lattice,context):
    class Concept:
        def __init__(self, c, b, t):
            self.c = c
            self.b = b
            self.t = t   

    Extents = [E for [E,I] in Lattice]
    dict = {}
	#creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    CL = [Concept(X,0,0) for X in Extents]
    for i in range(len(CL)):
        dict[i] = []
        for conc in CL:
            if conc.c.issubset(CL[i].c) and not set(CL[i].c).issubset(conc.c):
                dict[i].append(conc)

    #Calcul des classes d'équivalences
    end = 0
    while end == 0:
        end = 1
        for i in range(len(CL)):
            if CL[i].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1:
                    end = 0
                    CL[i].t = pow(2,(len(CL[i].c)))-sum
                    CL[i].b = 1

    signal = list()
    BooleanLattice = list(powerset(range(dimension)))

    for e in BooleanLattice :
        extent = PCA.Extent(PCA.Intent(set(e), context), context)
        for conc in CL :
            if set(conc.c) == set(extent) :
                signal.append(1/conc.t)#on file 1/taille de la classe d'équivalence comme signal
                break
    return signal

def Fourier_transform_lattice(nbObj,Lattice,context):
    signal = assignSignalLattice(nbObj, Lattice,context)
    setfunction = SFT.setfunctions.WrapSignal(signal)
    ft = setfunction.transform_sparse()
    return ft.coefs, ft.freqs


def lattice_distance_SP(L1,L2,nbObj,context1,context2):
    coefs1,freqs1 = Fourier_transform_lattice(nbObj,L1,context1)
    coefsToCompare1, _ = alignCoefsFreqsToCube (coefs1, freqs1, nbObj)
    coefs2,freqs2 = Fourier_transform_lattice(nbObj,L2,context2)
    coefsToCompare2, _ = alignCoefsFreqsToCube (coefs2, freqs2, nbObj)
    return float(distance.euclidean(coefsToCompare1,coefsToCompare2))


def assignSignalImplis(dimension,Implis,context):
    signal = list()
    BooleanLattice = list(powerset(range(dimension)))

    for e in BooleanLattice :
        closure = PCA.Intent(PCA.Extent(set(e), context), context)
        signal.append(len(closure))

    return signal

def Fourier_transform_implis(nbAtt,Implis,context):
    signal = assignSignalImplis(nbAtt,Implis,context)
    print(signal)
    setfunction = SFT.setfunctions.WrapSignal(signal)
    ft = setfunction.transform_sparse()
    print(ft.coefs)
    print(ft.freqs)
    return ft.coefs, ft.freqs

def logical_distance_SP(I1,I2,nbAtt,context1,context2):
    coefs1,freqs1 = Fourier_transform_implis(nbAtt,I1,context1)
    coefsToCompare1, _ = alignCoefsFreqsToCube (coefs1, freqs1, nbAtt)
    coefs2,freqs2 = Fourier_transform_implis(nbAtt,I2,context2)
    coefsToCompare2, _ = alignCoefsFreqsToCube (coefs2, freqs2, nbAtt)
    return float(distance.euclidean(coefsToCompare1,coefsToCompare2))

def lattice_distance_SP_naive(L1,L2,nbObj,C1,C2):
    signal1 = assignSignalLattice(nbObj,L1,C1)
    signal2 = assignSignalLattice(nbObj,L2,C2)
    return float(distance.euclidean(signal1,signal2))


def matrix_diff(M1,M2):
    M = copy.copy(M1)
    for i in range(len(M2)):
        for j in range(len(M2[i])):
            M[i][j] = M[i][j]-M2[i][j]
    return M

def L1_norm(M):
    s = 0
    for i in M:
        for j in i:
            s += abs(j)
    return s

def domenach_similarity(C1,C2,nbObj):
    M1 = []
    for i in range(int((nbObj*(nbObj-1))/2)):
        M1.append([0]*nbObj)
    M2 = []
    for i in range(int((nbObj*(nbObj-1))/2)):
        M2.append([0]*nbObj)
    ind = 0
    for i in range(nbObj):
        for j in range(i+1,nbObj):
            if j != i:
                for k in range(nbObj):
                    if k != i and k != j:
                        E11 = PCA.Extent(PCA.Intent(set([i,j]),C1),C1)
                        E21 = PCA.Extent(PCA.Intent(set([i,j,k]),C1),C1)
                        E12 = PCA.Extent(PCA.Intent(set([i,j]),C2),C2)
                        E22 = PCA.Extent(PCA.Intent(set([i,j,k]),C2),C2)
                        if len(E11) != len(E21):
                            M1[ind][k] = 1 
                        if len(E12) != len(E22):
                            M2[ind][k] = 1 
            ind += 1

    return L1_norm(matrix_diff(M1,M2))/(L1_norm(M1)+L1_norm(M2))

'''
def factual_distance(C1,C2,p):
    som = 0
    for i in range(C1[1]):
        for j in range(C1[2]):
            d = 0
            if [i,j] in C1[0]:
                d = 1
            if [i,j] in C2[0]:
                d = abs(d-1)
            som = som+pow(d,p)
    return pow(som,1.0/p)/pow(C1[1]*C1[2],1.0/p)
'''
def factual_distance(C1,C2,p):
    intersect = []
    for X in C1[0]:
        if X in C2[0]:
            intersect.append(X)
    return pow(pow(len(C1[0])-len(intersect),p)+pow(len(C2[0])-len(intersect),p),1.0/p)/(len(intersect)+pow(pow(len(C1[0])-len(intersect),p)+pow(len(C2[0])-len(intersect),p),1.0/p))


def conceptual_distance(L1,L2,p,q):
    nbTrucs = []
    Extents = [X[0] for X in L1]        
    nbTrucs.append(max([len(E) for E in Extents]))
    Intents = [X[1] for X in L1]        
    nbTrucs.append(max([len(I) for I in Intents]))
    EI1=[[E for [E,_] in L1],[I for [_,I] in L1]]
    EI2=[[E for [E,_] in L2],[I for [_,I] in L2]]
    R = [0,0]
    for sens in range(2):
        distances = 0
        for elem in range(nbTrucs[sens]):
            #trouver les introducteurs d'elem
            Sets1 = sorted(zip(EI1[0],EI1[1]), key=lambda pair: pair[sens])
            Intro1 = []
            for X in Sets1:
                if elem in X[sens]:
                    Intro1 = X[abs(sens-1)]
                    break
            Sets2 = sorted(zip(EI2[0],EI2[1]), key=lambda pair: pair[sens])
            Intro2 = []
            for X in Sets2:
                if elem in X[sens]:
                    Intro2 = X[abs(sens-1)]
                    break
            #calculer la distance entre les ensembles d'objets/attributes ayant elem dans leur dérivation
            nb1 = pow(2,len(Intro1))
            nb2 = pow(2,len(Intro2))
            nb12 = pow(2,len(set(Intro1).intersection(set(Intro2))))
            distance = pow(pow(abs(nb1-nb12),q)+pow(abs(nb2-nb12),q),1.0/q)
            if distance != 0:
                distance = distance/(nb12+distance)
            distances += pow(distance,p)
        R[sens] = pow(distances,1.0/p)/(pow(nbTrucs[sens],1.0/p))
    return min(R)

def logical_distance(I1,I2,nbAtt,p,q):
    somm = 0
    threads = []
    results = []
    for a in range(nbAtt):
        t = threading.Thread(target=logical_ter, args=(I1,I2,nbAtt,q,a,results))
        t.start()
        threads.append(t)
    for thread in threads:
        thread.join()  
    som = 0
    for x in results:
        som += pow(x,p)
    return pow(som,1.0/p)/(pow(nbAtt,1.0/p))   

def logical_ter(Imps1,Imps2,nbAtt,q,a,result):   
    premisses_de_a_1 = []
    premisses_de_a_2 = []
    for [A,B] in Imps1:
        if a in B:
            premisses_de_a_1.append(A)
    for [A,B] in Imps2:
        if a in B:
            premisses_de_a_2.append(A)
        
    if not(len(premisses_de_a_1) == 1 and premisses_de_a_1[0] == set()):
        premisses_de_a_1.append(set([a]))
    if not(len(premisses_de_a_2) == 1 and premisses_de_a_2[0] == set()):
        premisses_de_a_2.append(set([a]))


    #calculer les intersections des premisses
    intersections_premisses = []
    for A in premisses_de_a_1:
        for B in premisses_de_a_2:
            I = set(A).union(set(B))
            if I not in intersections_premisses:
                intersections_premisses.append(I)
    aVirer = []
    for I in intersections_premisses:
        virer = False
        for I2 in intersections_premisses:
            if I2.issubset(I) and len(I) != len(I2):
                virer = True
                break
        if virer:
            aVirer.append(I)
    for I in aVirer:
        intersections_premisses.remove(I)
    if len(premisses_de_a_1) == 0 and len(premisses_de_a_2) != 0:
        intersections_premisses = premisses_de_a_1
    if len(premisses_de_a_2) == 0 and len(premisses_de_a_1) != 0:
        intersections_premisses = premisses_de_a_2

    premisses_L1 = premisses_de_a_1
    premisses_L2 = premisses_de_a_2


    #Dedekind-Macneille completion des premisses
    if len(intersections_premisses) > 0:
        Comp1,_ = tree(intersections_premisses)
    else:
        Comp1 = []
    if len(premisses_L1) > 0:
        CompL1,_ = tree(premisses_L1)
    else:
        CompL1 = []
    if len(premisses_L2) > 0:
        CompL2,_ = tree(premisses_L2)
    else:
        CompL2 = []


    class Concept:
        def __init__(self, c, b, t):
            self.c = c
            self.b = b
            self.t = t
    #Calcul pour les intersections
    classe_max_intersection = 0
    dict = {}
    CL2 = [Concept(X,0,0) for X in Comp1]
    #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    for i in range(len(CL2)):
        dict[i] = []
        for conc in CL2:
            if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                dict[i].append(conc)
    #Calcul des classes d'équivalences
    Indices = sorted(zip(CL2,range(len(CL2))), key=lambda pair: pair[0].c)
    end = 0
    while end == 0:
        end = 1
        for i in Indices:
            if CL2[i[1]].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i[1]]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1 and (len(CL2[i[1]].c) > 0 or len(CL2) == 1):
                    end = 0
                    CL2[i[1]].t = pow(2,(nbAtt-len(CL2[i[1]].c)))-sum
                    classe_max_intersection += CL2[i[1]].t
                    CL2[i[1]].b = 1


    #Calcul pour L1
    classe_max_L1 = 0
    dict = {}
    CL2 = [Concept(X,0,0) for X in CompL1]
    #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    for i in range(len(CL2)):
        dict[i] = []
        for conc in CL2:
            if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                dict[i].append(conc)
    #Calcul des classes d'équivalences
    Indices = sorted(zip(CL2,range(len(CL2))), key=lambda pair: pair[0].c)
    end = 0
    while end == 0:
        end = 1
        for i in Indices:
            if CL2[i[1]].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i[1]]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1 and (len(CL2[i[1]].c) > 0 or len(CL2) == 1):
                    end = 0
                    CL2[i[1]].t = pow(2,(nbAtt-len(CL2[i[1]].c)))-sum
                    classe_max_L1 += CL2[i[1]].t
                    CL2[i[1]].b = 1
    #Calcul pour L2
    classe_max_L2 = 0
    dict = {}
    CL2 = [Concept(X,0,0) for X in CompL2]
    #creation du dictionnaire (moyen de faire mieux en prenant les extents par ordre croissant...)
    for i in range(len(CL2)):
        dict[i] = []
        for conc in CL2:
            if set(CL2[i].c).issubset(conc.c) and not set(conc.c).issubset(CL2[i].c):
                dict[i].append(conc)
    #Calcul des classes d'équivalences
    Indices = sorted(zip(CL2,range(len(CL2))), key=lambda pair: pair[0].c)
    end = 0
    while end == 0:
        end = 1
        for i in Indices:
            if CL2[i[1]].b == 0:
                aTraiter = 1
                sum = 0
                for conc2 in dict[i[1]]:
                    if conc2.b == 0:
                        aTraiter = 0
                        break
                    sum += conc2.t
                if aTraiter == 1 and (len(CL2[i[1]].c) > 0 or len(CL2) == 1):
                    end = 0
                    CL2[i[1]].t = pow(2,(nbAtt-len(CL2[i[1]].c)))-sum
                    classe_max_L2 += CL2[i[1]].t
                    CL2[i[1]].b = 1

    if classe_max_L1 > 0 or classe_max_L2 > 0:
        nb1 = classe_max_L1
        nb2 = classe_max_L2
        nb12 = classe_max_intersection
        Res = pow(pow(abs(nb1-nb12),q)+pow(abs(nb2-nb12),q),1.0/q)
        Res = Res/(nb12+pow(pow(abs(nb1-nb12),q)+pow(abs(nb2-nb12),q),1.0/q))
        result.append(Res)
    else:
        result.append(0) 




'''
Expes
'''


def completelyRandom(nbchange,nbObj,nbAtt,density,p,q):
    
    factual = []
    conceptual = []
    logical = []
    for i in range(nbchange):
        Context1 = randomContext(nbObj,nbAtt,density)
        Lattice1 = PCA.concepts(Context1)
        Implications1,_,_ = PCA.properPremises(Context1)
        Context2 = randomContext(nbObj,nbAtt,density)
        Lattice2 = PCA.concepts(Context2)
        Implications2,_,_ = PCA.properPremises(Context2)
        factual.append(factual_distance(Context1,Context2,p))
        conceptual.append(conceptual_distance(Lattice1,Lattice2,p,q))
        logical.append(logical_distance(Implications1,Implications2,nbAtt,p,q))
    f = open("results/aleatoire_factual","w")
    for x in factual:
        f.write(str(x)+" ")
    f.close()
    f = open("results/aleatoire_conceptual","w")
    for x in conceptual:
        f.write(str(x)+" ")
    f.close()
    f = open("results/aleatoire_logical","w")
    for x in logical:
        f.write(str(x)+" ")
    f.close()
    #factual/conceptual
    f = open("results/aleatoire_comp_facxconc","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(conceptual[x])+"\n")
    f.close()
    #factual/logical
    f = open("results/aleatoire_comp_facxlog","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(logical[x])+"\n")
    f.close()
    #conceptual/logical
    f = open("results/aleatoire_comp_concxlog","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(logical[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,conceptual)
    m13 = ss.pearsonr(factual,logical)
    m23 = ss.pearsonr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/aleatoire_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,conceptual)
    m13 = ss.spearmanr(factual,logical)
    m23 = ss.spearmanr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/aleatoire_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,conceptual)
    m13 = ss.kendalltau(factual,logical)
    m23 = ss.kendalltau(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/aleatoire_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()


def derivations(nbchange,nbObj,nbAtt,density,p,q):
    factual = []
    conceptual = []
    logical = []
    for i in range(nbchange):
        Context1 = randomContext(nbObj,nbAtt,density)
        Lattice1 = PCA.concepts(Context1)
        Implications1,_,_ = PCA.properPremises(Context1)
        Context2 = closeEnoughContext4(Context1,0.05)
        Lattice2 = PCA.concepts(Context2)
        Implications2,_,_ = PCA.properPremises(Context2)
        factual.append(factual_distance(Context1,Context2,p))
        conceptual.append(conceptual_distance(Lattice1,Lattice2,p,q))
        logical.append(logical_distance(Implications1,Implications2,nbAtt,p,q))
    f = open("results/derive_factual","w")
    for x in factual:
        f.write(str(x)+" ")
    f.close()
    f = open("results/derive_conceptual","w")
    for x in conceptual:
        f.write(str(x)+" ")
    f.close()
    f = open("results/derive_logical","w")
    for x in logical:
        f.write(str(x)+" ")
    f.close()
    #factual/conceptual
    f = open("results/derive_comp_facxconc","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(conceptual[x])+"\n")
    f.close()
    #factual/logical
    f = open("results/derive_comp_facxlog","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(logical[x])+"\n")
    f.close()
    #conceptual/logical
    f = open("results/derive_comp_concxlog","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(logical[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,conceptual)
    m13 = ss.pearsonr(factual,logical)
    m23 = ss.pearsonr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/derive_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,conceptual)
    m13 = ss.spearmanr(factual,logical)
    m23 = ss.spearmanr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/derive_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,conceptual)
    m13 = ss.kendalltau(factual,logical)
    m23 = ss.kendalltau(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/derive_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()

def progression(nbchange,nbObj,nbAtt,density,p,q):
    Context1 = randomContext(nbObj,nbAtt,density)
    Lattice1 = PCA.concepts(Context1)
    Implications1,_,_ = PCA.properPremises(Context1)
    factual = []
    conceptual = []
    logical = []
    ContextL = Context1
    for i in range(200):
        Context2 = closeEnoughContext4(ContextL,0.02)
        ContextL = Context2
        Lattice2 = PCA.concepts(Context2)
        Implications2,_,_ = PCA.properPremises(Context2)
        factual.append(factual_distance(Context1,Context2,p))
        conceptual.append(conceptual_distance(Lattice1,Lattice2,p,q))
        logical.append(logical_distance(Implications1,Implications2,nbAtt,p,q))
    f = open("results/prog_factual","w")
    for x in factual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/prog_conceptual","w")
    for x in conceptual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/prog_logical","w")
    for x in logical:
        f.write(str(x)+"\n")
    f.close()
    #factual/conceptual
    f = open("results/prog_comp_facxconc","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(conceptual[x])+"\n")
    f.close()
    #factual/logical
    f = open("results/prog_comp_facxlog","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(logical[x])+"\n")
    f.close()
    #conceptual/logical
    f = open("results/prog_comp_concxlog","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(logical[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,conceptual)
    m13 = ss.pearsonr(factual,logical)
    m23 = ss.pearsonr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/prog_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,conceptual)
    m13 = ss.spearmanr(factual,logical)
    m23 = ss.spearmanr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/prog_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,conceptual)
    m13 = ss.kendalltau(factual,logical)
    m23 = ss.kendalltau(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/prog_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()


def comparaisonDomenach(nbchange,nbObj,nbAtt,density,p,q):
    Context1 = randomContext(nbObj,nbAtt,density)
    Lattice1 = PCA.concepts(Context1)
    Implis1,_,_ = PCA.properPremises(Context1)
    factual = []
    conceptual = []
    logical = []
    domenach = []
    for i in range(nbchange):
        Context2 = randomContext(nbObj,nbAtt,density)
        Lattice2 = PCA.concepts(Context2)
        Implis2,_,_ = PCA.properPremises(Context2)
        factual.append(factual_distance(Context1,Context2,p))
        conceptual.append(conceptual_distance(Lattice1,Lattice2,p,q))
        logical.append(logical_distance(Implis1,Implis2,nbAtt,p,q))
        domenach.append(domenach_similarity(Context1,Context2,nbObj))
    f = open("results/domenach_domenach","w")
    for x in domenach:
        f.write(str(x)+" ")
    f.close()
    #factual/domenach
    f = open("results/domenach_comp_facxdom","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(domenach[x])+"\n")
    f.close()
    #conceptual/domenach
    f = open("results/domenach_comp_concxdom","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(domenach[x])+"\n")
    f.close()
    #logical/domenach
    f = open("results/domenach_comp_logxdom","w")
    for x in range(len(logical)):
        f.write(str(logical[x])+" "+str(domenach[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,domenach)
    m13 = ss.pearsonr(conceptual,domenach)
    m23 = ss.pearsonr(logical,domenach)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/domenach_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,domenach)
    m13 = ss.spearmanr(conceptual,domenach)
    m23 = ss.spearmanr(logical,domenach)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/domenach_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,domenach)
    m13 = ss.kendalltau(conceptual,domenach)
    m23 = ss.kendalltau(logical,domenach)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/domenach_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()

def comparaisonSP(nbchange,nbObj,nbAtt,density,p):
    Context1 = randomContext(nbObj,nbAtt,density)
    Lattice1 = PCA.concepts(Context1)
    factual = []
    naive = []
    SP = []
    for i in range(nbchange):
        Context2 = randomContext(nbObj,nbAtt,density)
        Lattice2 = PCA.concepts(Context2)
        factual.append(factual_distance(Context1,Context2,p))
        naive.append(lattice_distance_SP_naive(Lattice1,Lattice2,nbObj,Context1,Context2))
        SP.append(lattice_distance_SP(Lattice1,Lattice2,nbObj,Context1,Context2))
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,naive)
    m13 = ss.pearsonr(factual,SP)
    m23 = ss.pearsonr(naive,SP)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/SP_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,naive)
    m13 = ss.spearmanr(factual,SP)
    m23 = ss.spearmanr(naive,SP)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/SP_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,naive)
    m13 = ss.kendalltau(factual,SP)
    m23 = ss.kendalltau(naive,SP)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/SP_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()

def correlationGlissante(nbchange,nbObj,nbAtt,density,fenetre,p,q):
    Context1 = randomContext(nbObj,nbAtt,density)
    Lattice1 = PCA.concepts(Context1)
    Implications1,_,_ = PCA.properPremises(Context1)
    FCPearson = []
    FCSpearman = []
    FCKendall = []
    FLPearson = []
    FLSpearman = []
    FLKendall = []
    CLPearson = []
    CLSpearman = []
    CLKendall = []
    for p in range(1,21):    
        factual = []
        conceptual = []
        logical = []
        for i in range(nbchange):
            Context2 = closeEnoughContext4(Context1,0.025*p)
            Lattice2 = PCA.concepts(Context2)
            Implications2,_,_ = PCA.properPremises(Context2)
            factual.append(factual_distance(Context1,Context2,p))
            conceptual.append(conceptual_distance(Lattice1,Lattice2,p,q))
            logical.append(logical_distance(Implications1,Implications2,nbAtt,p,q))
        FCPearson.append(ss.pearsonr(factual,conceptual)[0])
        FCSpearman.append(ss.spearmanr(factual,conceptual)[0])
        FCKendall.append(ss.kendalltau(factual,conceptual)[0])
        FLPearson.append(ss.pearsonr(factual,logical)[0])
        FLSpearman.append(ss.spearmanr(factual,logical)[0])
        FLKendall.append(ss.kendalltau(factual,logical)[0])
        CLPearson.append(ss.pearsonr(conceptual,logical)[0])
        CLSpearman.append(ss.spearmanr(conceptual,logical)[0])
        CLKendall.append(ss.kendalltau(conceptual,logical)[0])   
    f = open("results/corrGlissante_pearson_FC","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(FCPearson[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_spearman_FC","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(FCSpearman[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_kendall_FC","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(FCKendall[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_pearson_FL","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(FLPearson[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_spearman_FL","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(FLSpearman[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_kendall_FL","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(FLKendall[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_pearson_CL","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(CLPearson[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_spearman_CL","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(CLSpearman[i])+"\n")
    f.close() 
    f = open("results/corrGlissante_kendall_CL","w")
    for i in range(20):
        f.write(str(0.025*(i+1))+" "+str(CLKendall[i])+"\n")
    f.close() 



def fallFromFull(nbObj,nbAtt,p,q):
    nbchange = 500
    factual = []
    conceptual = []
    logical = []
    c = []
    cf = []
    for i in range(nbObj):
        for j in range(nbAtt):
            c+=[[i,j]]
            cf+=[[i,j]]
    Context = (c,nbObj,nbAtt)
    ContextFull = (cf,nbObj,nbAtt)
    ImplicationsFull,_,_ = PCA.properPremises(ContextFull)
    LatticeFull = [[set(range(nbObj)),set(range(nbAtt))]]
    for i in range(nbchange):
        if i != 0:
            Lattice2 = PCA.concepts(Context)
            Implications2,_,_ = PCA.properPremises(Context)
        else:
            Lattice2 = LatticeFull
            Implications2 = ImplicationsFull
        factual.append(factual_distance(ContextFull,Context,p))
        conceptual.append(conceptual_distance(LatticeFull,Lattice2,p,q))
        logical.append(logical_distance(ImplicationsFull,Implications2,nbAtt,p,q))
        rand = random.randint(0,len(Context[0])-1)
        Context[0].pop(rand)
    f = open("results/F2E_factual","w")
    for x in factual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/F2E_conceptual","w")
    for x in conceptual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/F2E_logical","w")
    for x in logical:
        f.write(str(x)+"\n")
    f.close()
    #factual/conceptual
    f = open("results/F2E_comp_facxconc","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(conceptual[x])+"\n")
    f.close()
    #factual/logical
    f = open("results/F2E_comp_facxlog","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(logical[x])+"\n")
    f.close()
    #conceptual/logical
    f = open("results/F2E_comp_concxlog","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(logical[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,conceptual)
    m13 = ss.pearsonr(factual,logical)
    m23 = ss.pearsonr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2E_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,conceptual)
    m13 = ss.spearmanr(factual,logical)
    m23 = ss.spearmanr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2E_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,conceptual)
    m13 = ss.kendalltau(factual,logical)
    m23 = ss.kendalltau(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2E_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()     


def fallFromFullConcepts(nbObj,nbAtt,p,q):
    nbchange = 500
    factual = []
    conceptual = []
    logical = []
    c = []
    cf = []
    for i in range(nbObj):
        for j in range(nbAtt):
            c+=[[i,j]]
            cf+=[[i,j]]
    Context = (c,nbObj,nbAtt)
    ContextFull = (cf,nbObj,nbAtt)
    ImplicationsFull,_,_ = PCA.properPremises(ContextFull)
    LatticeFull = [[set(range(nbObj)),set(range(nbAtt))]]
    for i in range(nbchange):
        if i != 0:
            Lattice2 = PCA.concepts(Context)
            Implications2,_,_ = PCA.properPremises(Context)
        else:
            Lattice2 = LatticeFull
            Implications2 = ImplicationsFull
        factual.append(factual_distance(ContextFull,Context,p))
        conceptual.append(conceptual_distance(LatticeFull,Lattice2,p,q))
        logical.append(logical_distance(ImplicationsFull,Implications2,nbAtt,p,q))
        rand = random.randint(0,len(Context[0])-1)
        maxVal = nbObj*nbAtt
        maxi = []
        for j in range(len(Context[0])):
            count = 0
            for [x2,y2] in Context[0]:
                if x2 == Context[0][j][0]:
                    count+=1/nbAtt
                if y2 == Context[0][j][1]:
                    count+=1/nbObj
            if count == maxVal:
                maxi+=[j]
            if count < maxVal:
                maxi=[j]
                maxVal = count
        if len(maxi) > 1:
            rand = random.randint(0,len(maxi)-1)
        else:
            rand = 0
        Context[0].pop(maxi[rand])
    f = open("results/F2ECmin_factual","w")
    for x in factual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/F2ECmin_conceptual","w")
    for x in conceptual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/F2ECmin_logical","w")
    for x in logical:
        f.write(str(x)+"\n")
    f.close()
    #factual/conceptual
    f = open("results/F2ECmin_comp_facxconc","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(conceptual[x])+"\n")
    f.close()
    #factual/logical
    f = open("results/F2ECmin_comp_facxlog","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(logical[x])+"\n")
    f.close()
    #conceptual/logical
    f = open("results/F2ECmin_comp_concxlog","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(logical[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,conceptual)
    m13 = ss.pearsonr(factual,logical)
    m23 = ss.pearsonr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2ECmin_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,conceptual)
    m13 = ss.spearmanr(factual,logical)
    m23 = ss.spearmanr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2ECmin_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,conceptual)
    m13 = ss.kendalltau(factual,logical)
    m23 = ss.kendalltau(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2ECmin_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()     


def fallFromFullConcepts2(nbObj,nbAtt,p,q):
    nbchange = 500
    factual = []
    conceptual = []
    logical = []
    c = []
    cf = []
    for i in range(nbObj):
        for j in range(nbAtt):
            c+=[[i,j]]
            cf+=[[i,j]]
    Context = (c,nbObj,nbAtt)
    ContextFull = (cf,nbObj,nbAtt)
    ImplicationsFull,_,_ = PCA.properPremises(ContextFull)
    LatticeFull = [[set(range(nbObj)),set(range(nbAtt))]]
    elem = 0
    for i in range(nbchange):
        if i != 0:
            Lattice2 = PCA.concepts(Context)
            Implications2,_,_ = PCA.properPremises(Context)
        else:
            Lattice2 = LatticeFull
            Implications2 = ImplicationsFull
        factual.append(factual_distance(ContextFull,Context,p))
        conceptual.append(conceptual_distance(LatticeFull,Lattice2,p,q))
        logical.append(logical_distance(ImplicationsFull,Implications2,nbAtt,p,q))
        rand = random.randint(0,len(Context[0])-1)
        Context[0].pop(0)
        elem+=1
    f = open("results/F2ECligne_factual","w")
    for x in factual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/F2ECligne_conceptual","w")
    for x in conceptual:
        f.write(str(x)+"\n")
    f.close()
    f = open("results/F2ECligne_logical","w")
    for x in logical:
        f.write(str(x)+"\n")
    f.close()
    #factual/conceptual
    f = open("results/F2ECligne_comp_facxconc","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(conceptual[x])+"\n")
    f.close()
    #factual/logical
    f = open("results/F2ECligne_comp_facxlog","w")
    for x in range(len(factual)):
        f.write(str(factual[x])+" "+str(logical[x])+"\n")
    f.close()
    #conceptual/logical
    f = open("results/F2ECligne_comp_concxlog","w")
    for x in range(len(conceptual)):
        f.write(str(conceptual[x])+" "+str(logical[x])+"\n")
    f.close()
    #matrices de corrélation : pearson
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.pearsonr(factual,conceptual)
    m13 = ss.pearsonr(factual,logical)
    m23 = ss.pearsonr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2ECligne_matrice_pearson","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : spearman
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.spearmanr(factual,conceptual)
    m13 = ss.spearmanr(factual,logical)
    m23 = ss.spearmanr(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2ECligne_matrice_spearman","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()
    #matrices de corrélation : kendall
    M = []
    l1 = []
    l2 = []
    l3 = []
    m12 = ss.kendalltau(factual,conceptual)
    m13 = ss.kendalltau(factual,logical)
    m23 = ss.kendalltau(conceptual,logical)
    l1.append((1,0))
    l1.append(m12)
    l1.append(m13)
    M.append(l1)
    l2.append(m12)
    l2.append((1,0))
    l2.append(m23)
    M.append(l2)
    l3.append(m13)
    l3.append(m23)
    l3.append((1,0))
    M.append(l3)
    f = open("results/F2ECligne_matrice_kendall","w")
    for i in range(3):
        for j in range(3):
            f.write(str(M[i][j])+" ")
        f.write("\n")
    f.close()


def expesPapier():

    nbchange = 1500
    nbObj = 50
    nbAtt = 10
    density = 0.3
    p = 2
    q = 1


    #1000 random contexts compared to a single one
    completelyRandom(nbchange,nbObj,nbAtt,density,p,q)
    
    #1000 contexts derived from an initial one
    derivations(nbchange,nbObj,nbAtt,density,p,q)
    
    #Progression 200x from an initial context
    progression(200,nbObj,nbAtt,density,p,q)

    #comparison with domenach
    comparaisonDomenach(1000,nbObj,nbAtt,density,p,q)

    #comparaison SP
    comparaisonSP(nbchange,nbObj,nbAtt,density)

    #sliding window for correlations
    correlationGlissante(nbchange,nbObj,nbAtt,density,10,p,q)

    #Distance to the full context while removing crosses
    fallFromFullConcepts2(nbObj,nbAtt,p,q)

expesPapier()
